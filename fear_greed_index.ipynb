{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries\n"
      ],
      "metadata": {
        "id": "uvN5abU1BtWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6VpQYaXJBrf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction from Zip File\n"
      ],
      "metadata": {
        "id": "kLphthzaCB7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create extraction directory\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Unzip Datasets\n",
        "with zipfile.ZipFile(\"fear_greed_index.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "with zipfile.ZipFile(\"historical_data.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "\n",
        "print(\"Files extracted successfully.\")\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk(\"data\"):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ],
      "metadata": {
        "id": "V1el2BZxBxdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "NAZScDk-CE-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fear_greed = pd.read_csv(\"data/fear_greed_index.csv\")\n",
        "historical = pd.read_csv(\"data/historical_data.csv\")"
      ],
      "metadata": {
        "id": "o41wxNSeB6g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values / duplicates"
      ],
      "metadata": {
        "id": "oi0YK08ACbuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_dataset(df, name):\n",
        "    print(f\"========== {name} ==========\")\n",
        "    print(\"Shape:\", df.shape)\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
        "    print(\"\\n\")\n",
        "\n",
        "inspect_dataset(fear_greed, \"Fear & Greed Index\")\n",
        "inspect_dataset(historical, \"Historical Trading Data\")"
      ],
      "metadata": {
        "id": "nO7t_WgSB-i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion of Dataset and Aligning by date"
      ],
      "metadata": {
        "id": "xOZISQtJCqwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fear_greed['date'] = pd.to_datetime(fear_greed['date'], errors='coerce')\n",
        "\n",
        "\n",
        "historical['Timestamp'] = pd.to_numeric(historical['Timestamp'], errors='coerce')\n",
        "\n",
        "# Convert from milliseconds to datetime\n",
        "historical['datetime'] = pd.to_datetime(historical['Timestamp'], unit='ms', errors='coerce')\n",
        "\n",
        "#daily date column\n",
        "historical['date'] = historical['datetime'].dt.date\n",
        "historical['date'] = pd.to_datetime(historical['date'])\n",
        "\n",
        "print(\"Timestamp conversion completed successfully.\")\n",
        "# Merge datasets on 'date'\n",
        "merged_df = pd.merge(\n",
        "    historical,\n",
        "    fear_greed[['date', 'value', 'classification']],\n",
        "    on='date',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"Merged Dataset Shape:\", merged_df.shape)\n",
        "display(merged_df.head())"
      ],
      "metadata": {
        "id": "fGS5E-fzCTld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daily PnL per trader (or per account)"
      ],
      "metadata": {
        "id": "9cNQLzTODKuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean Closed PnL\n",
        "\n",
        "merged_df['Closed PnL'] = pd.to_numeric(merged_df['Closed PnL'], errors='coerce')\n",
        "\n",
        "# Replace missing with 0\n",
        "merged_df['Closed PnL'] = merged_df['Closed PnL'].fillna(0)\n",
        "\n",
        "print(\"PnL cleaned.\")\n",
        "#daily PnL\n",
        "daily_pnl = (\n",
        "    merged_df\n",
        "    .groupby(['Account', 'date'])['Closed PnL']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(daily_pnl.head())\n"
      ],
      "metadata": {
        "id": "fx7Ntx-eCqAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Win rate, average trade size"
      ],
      "metadata": {
        "id": "WKwnj-U4DmWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Win Rate per Account\n",
        "merged_df['is_win'] = np.where(merged_df['Closed PnL'] > 0, 1, 0)\n",
        "\n",
        "win_rate = (\n",
        "    merged_df\n",
        "    .groupby('Account')\n",
        "    .agg(\n",
        "        total_trades=('Closed PnL', 'count'),\n",
        "        winning_trades=('is_win', 'sum')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "win_rate['win_rate'] = win_rate['winning_trades'] / win_rate['total_trades']\n",
        "display(win_rate.head())\n",
        "\n",
        "# Average Trade Size\n",
        "avg_trade_size = (\n",
        "    merged_df\n",
        "    .groupby('Account')\n",
        "    .agg(\n",
        "        avg_size_tokens=('Size Tokens', 'mean'),\n",
        "        avg_size_usd=('Size USD', 'mean')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "display(avg_trade_size.head())"
      ],
      "metadata": {
        "id": "9x_eL_vFC-GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leverage Distribution"
      ],
      "metadata": {
        "id": "bEieTMYxDrdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['leverage'] = merged_df['Size USD'] / merged_df['Execution Price']\n",
        "\n",
        "leverage_stats = (\n",
        "    merged_df\n",
        "    .groupby('Account')['leverage']\n",
        "    .describe()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(leverage_stats.head())"
      ],
      "metadata": {
        "id": "AsJT2CSpDc1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of trades per day"
      ],
      "metadata": {
        "id": "9OhmryVdDuvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trades_per_day = (\n",
        "    merged_df\n",
        "    .groupby('date')\n",
        "    .size()\n",
        "    .reset_index(name='number_of_trades')\n",
        ")\n",
        "\n",
        "display(trades_per_day.head())"
      ],
      "metadata": {
        "id": "4L85mZkUDsvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long/Short Ratio"
      ],
      "metadata": {
        "id": "Q1S6QIJ5D2IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "long_short = (\n",
        "    merged_df\n",
        "    .groupby(['Account', 'Side'])\n",
        "    .size()\n",
        "    .unstack(fill_value=0)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "if 'BUY' in long_short.columns and 'SELL' in long_short.columns:\n",
        "    long_short['long_short_ratio'] = long_short['BUY'] / (long_short['SELL'] + 1e-6)\n",
        "\n",
        "display(long_short.head())"
      ],
      "metadata": {
        "id": "KDRToBfUDybh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining all account metrics"
      ],
      "metadata": {
        "id": "rbay0kiMEDjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_metrics = (\n",
        "    win_rate\n",
        "    .merge(avg_trade_size, on='Account', how='left')\n",
        ")\n",
        "\n",
        "display(final_metrics.head())"
      ],
      "metadata": {
        "id": "WymBX4QVD6B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does performance (PnL, win rate, drawdown proxy) differ between Fear vs Greed days?"
      ],
      "metadata": {
        "id": "nPwHcqK3EZPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fear_labels = ['Fear', 'Extreme Fear']\n",
        "greed_labels = ['Greed', 'Extreme Greed']\n",
        "\n",
        "merged_df['sentiment_group'] = np.where(\n",
        "    merged_df['classification'].isin(fear_labels),\n",
        "    'Fear',\n",
        "    np.where(\n",
        "        merged_df['classification'].isin(greed_labels),\n",
        "        'Greed',\n",
        "        'Neutral'\n",
        "    )\n",
        ")\n",
        "\n",
        "sentiment_distribution = merged_df['sentiment_group'].value_counts()\n",
        "display(sentiment_distribution)\n",
        "\n",
        "#Performance Comparison\n",
        "performance_comparison = (\n",
        "    merged_df\n",
        "    .groupby('sentiment_group')\n",
        "    .agg(\n",
        "        avg_pnl=('Closed PnL', 'mean'),\n",
        "        median_pnl=('Closed PnL', 'median'),\n",
        "        win_rate=('is_win', 'mean'),\n",
        "        trade_count=('Closed PnL', 'count')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(performance_comparison)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=performance_comparison, x='sentiment_group', y='avg_pnl')\n",
        "plt.title(\"Average PnL by Sentiment Group\")\n",
        "plt.ylabel(\"Average PnL\")\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UgGhHoxGEHXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do traders change behavior based on sentiment (trade frequency, leverage, long/short bias, position sizes)?"
      ],
      "metadata": {
        "id": "hWNxPIaHEsbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "behavior_analysis = (\n",
        "    merged_df\n",
        "    .groupby('sentiment_group')\n",
        "    .agg(\n",
        "        avg_leverage=('leverage', 'mean'),\n",
        "        avg_trade_size=('Size USD', 'mean'),\n",
        "        total_trades=('Account', 'count'),\n",
        "        long_ratio=('Side', lambda x: (x == 'BUY').mean())\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(behavior_analysis)\n",
        "\n",
        "fig, axes = plt.subplots(1,2, figsize=(14,5))\n",
        "\n",
        "sns.barplot(data=behavior_analysis, x='sentiment_group', y='avg_leverage', ax=axes[0])\n",
        "axes[0].set_title(\"Average Leverage by Sentiment\")\n",
        "\n",
        "sns.barplot(data=behavior_analysis, x='sentiment_group', y='avg_trade_size', ax=axes[1])\n",
        "axes[1].set_title(\"Average Trade Size by Sentiment\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h6CHzUXuEcNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# High vs Low Leverage Traders\n",
        "account_leverage = (\n",
        "    merged_df\n",
        "    .groupby('Account')['leverage']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "threshold = account_leverage['leverage'].median()\n",
        "account_leverage['leverage_segment'] = np.where(\n",
        "    account_leverage['leverage'] >= threshold,\n",
        "    'High Leverage',\n",
        "    'Low Leverage'\n",
        ")\n",
        "display(account_leverage.head())"
      ],
      "metadata": {
        "id": "evLrdOulE1vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Frequent vs Infrequent Traders\n",
        "trade_counts = (\n",
        "    merged_df\n",
        "    .groupby('Account')\n",
        "    .size()\n",
        "    .reset_index(name='total_trades')\n",
        ")\n",
        "freq_threshold = trade_counts['total_trades'].median()\n",
        "trade_counts['frequency_segment'] = np.where(\n",
        "    trade_counts['total_trades'] >= freq_threshold,\n",
        "    'Frequent',\n",
        "    'Infrequent'\n",
        ")\n",
        "display(trade_counts.head())"
      ],
      "metadata": {
        "id": "6XuPo7vQE5JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consistent Traders\n",
        "account_win = (\n",
        "    merged_df\n",
        "    .groupby('Account')['is_win']\n",
        "    .mean()\n",
        "    .reset_index(name='win_rate')\n",
        ")\n",
        "\n",
        "win_threshold = account_win['win_rate'].median()\n",
        "\n",
        "account_win['consistency_segment'] = np.where(\n",
        "    account_win['win_rate'] >= win_threshold,\n",
        "    'Consistent',\n",
        "    'Inconsistent'\n",
        ")\n",
        "\n",
        "display(account_win.head())"
      ],
      "metadata": {
        "id": "phciSL0OFE0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment vs Performance\n",
        "\n",
        "segment_analysis = (\n",
        "    merged_df\n",
        "    .merge(account_leverage[['Account','leverage_segment']], on='Account')\n",
        "    .merge(account_win[['Account','consistency_segment']], on='Account')\n",
        ")\n",
        "\n",
        "segment_performance = (\n",
        "    segment_analysis\n",
        "    .groupby(['leverage_segment','consistency_segment'])\n",
        "    .agg(\n",
        "        avg_pnl=('Closed PnL','mean'),\n",
        "        win_rate=('is_win','mean'),\n",
        "        avg_leverage=('leverage','mean')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(segment_performance)"
      ],
      "metadata": {
        "id": "gzKfZCkdFKpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization - Segment Performance\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(data=segment_performance,\n",
        "            x='leverage_segment',\n",
        "            y='avg_pnl',\n",
        "            hue='consistency_segment')\n",
        "\n",
        "plt.title(\"Segment Performance Comparison\")\n",
        "plt.ylabel(\"Average PnL\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LZO-ekfeFbej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drawdown Proxy\n",
        "\n",
        "\n",
        "daily_account_pnl = (\n",
        "    merged_df\n",
        "    .groupby(['Account','date'])['Closed PnL']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "daily_account_pnl['cumulative_pnl'] = (\n",
        "    daily_account_pnl\n",
        "    .groupby('Account')['Closed PnL']\n",
        "    .cumsum()\n",
        ")\n",
        "\n",
        "daily_account_pnl['rolling_max'] = (\n",
        "    daily_account_pnl\n",
        "    .groupby('Account')['cumulative_pnl']\n",
        "    .cummax()\n",
        ")\n",
        "\n",
        "daily_account_pnl['drawdown'] = (\n",
        "    daily_account_pnl['cumulative_pnl'] -\n",
        "    daily_account_pnl['rolling_max']\n",
        ")\n",
        "\n",
        "display(daily_account_pnl.head())"
      ],
      "metadata": {
        "id": "I2bTiqh7Fc58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part C"
      ],
      "metadata": {
        "id": "bUsaQbtuH3ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Account-level metrics\n",
        "account_metrics = (\n",
        "    merged_df\n",
        "    .groupby('Account')\n",
        "    .agg(\n",
        "        avg_leverage=('leverage','mean'),\n",
        "        win_rate=('is_win','mean'),\n",
        "        total_trades=('Account','count')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Define thresholds\n",
        "leverage_threshold = account_metrics['avg_leverage'].median()\n",
        "win_threshold = account_metrics['win_rate'].median()\n",
        "\n",
        "account_metrics['leverage_segment'] = np.where(\n",
        "    account_metrics['avg_leverage'] >= leverage_threshold,\n",
        "    'High Leverage',\n",
        "    'Low Leverage'\n",
        ")\n",
        "\n",
        "account_metrics['consistency_segment'] = np.where(\n",
        "    account_metrics['win_rate'] >= win_threshold,\n",
        "    'Consistent',\n",
        "    'Inconsistent'\n",
        ")\n",
        "\n",
        "account_metrics.head()"
      ],
      "metadata": {
        "id": "SavV99j5H3e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.merge(\n",
        "    account_metrics[['Account','leverage_segment','consistency_segment']],\n",
        "    on='Account',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "513c2lLQIOMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy 1 - Sentiment-Based Leverage Control"
      ],
      "metadata": {
        "id": "n-64oCsIICXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STRATEGY 1: Adjust leverage\n",
        "def strategy1_adjust_leverage(row):\n",
        "\n",
        "    lev = row['leverage']\n",
        "\n",
        "    # Fear regime\n",
        "    if row['sentiment_group'] == 'Fear':\n",
        "        if row['leverage_segment'] == 'High Leverage' or row['consistency_segment'] == 'Inconsistent':\n",
        "            return lev * 0.7\n",
        "        return lev\n",
        "\n",
        "    # Greed regime\n",
        "    if row['sentiment_group'] == 'Greed':\n",
        "        if row['consistency_segment'] == 'Consistent':\n",
        "            return lev * 1.1\n",
        "        return lev\n",
        "\n",
        "    return lev\n",
        "\n",
        "merged_df['adjusted_leverage_s1'] = merged_df.apply(strategy1_adjust_leverage, axis=1)"
      ],
      "metadata": {
        "id": "2KG61rHPIJIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['adjusted_pnl_s1'] = (\n",
        "    merged_df['Closed PnL'] *\n",
        "    (merged_df['adjusted_leverage_s1'] / merged_df['leverage'])\n",
        ")"
      ],
      "metadata": {
        "id": "LpQdfpzVIURS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy 2 - High-Risk Trader Controls"
      ],
      "metadata": {
        "id": "h5v8zXehIVW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['risk_tier'] = np.where(\n",
        "    (merged_df['leverage_segment'] == 'High Leverage') &\n",
        "    (merged_df['consistency_segment'] == 'Inconsistent'),\n",
        "    'Tier 3',\n",
        "    'Tier 1/2'\n",
        ")"
      ],
      "metadata": {
        "id": "qTy99IEDIaoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strategy2_adjust(row):\n",
        "\n",
        "    lev = row['leverage']\n",
        "\n",
        "    if row['risk_tier'] == 'Tier 3':\n",
        "        return lev * 0.6  # reduce 40%\n",
        "\n",
        "    return lev\n",
        "\n",
        "merged_df['adjusted_leverage_s2'] = merged_df.apply(strategy2_adjust, axis=1)\n",
        "\n",
        "merged_df['adjusted_pnl_s2'] = (\n",
        "    merged_df['Closed PnL'] *\n",
        "    (merged_df['adjusted_leverage_s2'] / merged_df['leverage'])\n",
        ")"
      ],
      "metadata": {
        "id": "GJ4AzN8RIZhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison = pd.DataFrame({\n",
        "    'Original Avg PnL': [merged_df['Closed PnL'].mean()],\n",
        "    'Strategy 1 Avg PnL': [merged_df['adjusted_pnl_s1'].mean()],\n",
        "    'Strategy 2 Avg PnL': [merged_df['adjusted_pnl_s2'].mean()]\n",
        "})\n",
        "\n",
        "comparison"
      ],
      "metadata": {
        "id": "G7kxGvlEIeNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_drawdown(series):\n",
        "    cumulative = series.cumsum()\n",
        "    rolling_max = cumulative.cummax()\n",
        "    drawdown = cumulative - rolling_max\n",
        "    return drawdown.min()\n",
        "\n",
        "drawdown_comparison = pd.DataFrame({\n",
        "    'Original DD': [calculate_drawdown(merged_df['Closed PnL'])],\n",
        "    'Strategy1 DD': [calculate_drawdown(merged_df['adjusted_pnl_s1'])],\n",
        "    'Strategy2 DD': [calculate_drawdown(merged_df['adjusted_pnl_s2'])]\n",
        "})\n",
        "\n",
        "drawdown_comparison"
      ],
      "metadata": {
        "id": "uurvnoJ2If4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Original','Strategy 1','Strategy 2']\n",
        "values = [\n",
        "    merged_df['Closed PnL'].mean(),\n",
        "    merged_df['adjusted_pnl_s1'].mean(),\n",
        "    merged_df['adjusted_pnl_s2'].mean()\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.bar(labels, values)\n",
        "plt.title(\"Average PnL Comparison\")\n",
        "plt.ylabel(\"Average PnL\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXP2JZrvIhne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus Part 1 - Predictive Model"
      ],
      "metadata": {
        "id": "v8O5lkmoF0Ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create daily trader-level dataset\n",
        "# Ensure sorted\n",
        "merged_df = merged_df.sort_values(['Account', 'date'])\n",
        "\n",
        "daily_df = (\n",
        "    merged_df\n",
        "    .groupby(['Account', 'date'])\n",
        "    .agg(\n",
        "        daily_pnl=('Closed PnL', 'sum'),\n",
        "        avg_leverage=('leverage', 'mean'),\n",
        "        trades=('Account', 'count'),\n",
        "        win_rate=('is_win', 'mean'),\n",
        "        avg_trade_size=('Size USD', 'mean'),\n",
        "        long_ratio=('Side', lambda x: (x == 'BUY').mean()),\n",
        "        sentiment_value=('value', 'mean')\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "daily_df.head()"
      ],
      "metadata": {
        "id": "LQQ1CdAfFek9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create next-day target\n",
        "daily_df = daily_df.sort_values(['Account', 'date'])\n",
        "\n",
        "daily_df['next_day_pnl'] = (\n",
        "    daily_df\n",
        "    .groupby('Account')['daily_pnl']\n",
        "    .shift(-1)\n",
        ")\n",
        "\n",
        "daily_df['next_day_profitable'] = (\n",
        "    daily_df['next_day_pnl'] > 0\n",
        ").astype(int)\n",
        "\n",
        "# Remove last-day NaNs\n",
        "daily_df = daily_df.dropna()\n",
        "\n",
        "daily_df.head()"
      ],
      "metadata": {
        "id": "Ce4FGjnYGNwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "features = [\n",
        "    'avg_leverage',\n",
        "    'trades',\n",
        "    'win_rate',\n",
        "    'avg_trade_size',\n",
        "    'long_ratio',\n",
        "    'sentiment_value'\n",
        "]\n",
        "\n",
        "X = daily_df[features]\n",
        "y = daily_df['next_day_profitable']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "59-Vbe7jGTWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model interpretation\n",
        "\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Coefficient': model.coef_[0]\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "coefficients"
      ],
      "metadata": {
        "id": "4MljQkcJGXxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus Part 2 - Trader Clustering"
      ],
      "metadata": {
        "id": "HzlDISvcGdUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create account-level summary\n",
        "account_summary = (\n",
        "    merged_df\n",
        "    .groupby('Account')\n",
        "    .agg(\n",
        "        avg_leverage=('leverage','mean'),\n",
        "        win_rate=('is_win','mean'),\n",
        "        avg_trade_size=('Size USD','mean'),\n",
        "        total_trades=('Account','count'),\n",
        "        long_ratio=('Side', lambda x: (x=='BUY').mean())\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "account_summary.head()"
      ],
      "metadata": {
        "id": "dKBvB8PSGcIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering traders\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "cluster_features = [\n",
        "    'avg_leverage',\n",
        "    'win_rate',\n",
        "    'avg_trade_size',\n",
        "    'total_trades',\n",
        "    'long_ratio'\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(account_summary[cluster_features])\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "account_summary['cluster'] = kmeans.fit_predict(scaled)\n",
        "\n",
        "account_summary.head()"
      ],
      "metadata": {
        "id": "-C_vMAF6GimY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    data=account_summary,\n",
        "    x='avg_leverage',\n",
        "    y='win_rate',\n",
        "    hue='cluster',\n",
        "    palette='Set2'\n",
        ")\n",
        "plt.title(\"Trader Behavioral Clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5vLV2vEgGoTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profile = (\n",
        "    account_summary\n",
        "    .groupby('cluster')[cluster_features]\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "cluster_profile"
      ],
      "metadata": {
        "id": "eYinSZl_GrGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus Part 3 - Streamlit Dashboard"
      ],
      "metadata": {
        "id": "b7lgL7JXGxt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "lvOD0NliG6OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "st.title(\"Trader Behavior Insights Dashboard\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload merged dataset (CSV)\")\n",
        "\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "\n",
        "    st.subheader(\"Sentiment Distribution\")\n",
        "    st.bar_chart(df['sentiment_group'].value_counts())\n",
        "\n",
        "    st.subheader(\"Average PnL by Sentiment\")\n",
        "    st.bar_chart(df.groupby('sentiment_group')['Closed PnL'].mean())\n",
        "\n",
        "    st.subheader(\"Leverage Distribution\")\n",
        "    st.bar_chart(df.groupby('sentiment_group')['leverage'].mean())\n",
        "\n",
        "    st.subheader(\"Top 10 Traders by PnL\")\n",
        "    top_traders = df.groupby('Account')['Closed PnL'].sum().sort_values(ascending=False).head(10)\n",
        "    st.bar_chart(top_traders)"
      ],
      "metadata": {
        "id": "zSR5cRp1GwxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}